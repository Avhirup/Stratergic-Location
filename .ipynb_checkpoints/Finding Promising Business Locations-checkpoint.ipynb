{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategic Location using Facebook Analytics\n",
    "\n",
    "If you were to open your own cafe, would you not want to effortlessly identify the most suitable location to set up your shop? Choosing an optimal physical location is a critical decision for numerous businesses, as many factors contribute to the final choice of the location.\n",
    "Features selected:\n",
    "* category of cafe\n",
    "* category of neighboring cafes\n",
    "* checkins of localities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-127f6945807d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniqueCategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJsontoDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'getData/fbData.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mfood_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munique_categories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterFoodRelated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-127f6945807d>\u001b[0m in \u001b[0;36mJsontoDataFrame\u001b[0;34m(jsonFile)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mJsontoDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit)\u001b[0m\n\u001b[1;32m    209\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    210\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'series'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 496\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def JsontoDataFrame(jsonFile):\n",
    "    data=pd.read_json(jsonFile)\n",
    "    data=data.as_matrix()\n",
    "    data= data.transpose()\n",
    "    data=pd.DataFrame(data,columns=['Category','Check-Ins','Latitude','Likes','Longitude','Name'])\n",
    "    return data\n",
    "\n",
    "def filterFoodRelated(data):\n",
    "    totalIndex=0\n",
    "    remIndex=[]\n",
    "    keepIndex=[]\n",
    "    uniqueCategories=[]\n",
    "    frConstraints=['Diner','Fruit','Vegetable','Caterer','Bar','Pub','Grill','Hotel','Restaurant','Lounge','Pizza Place','Dessert Shop','Coffee','Food','Beverage','Cafe']\n",
    "    \n",
    "    for index,rows in data.iterrows():\n",
    "        #print index,rows['Category']\n",
    "        for cat in rows['Category']:\n",
    "            categorysublist=cat.split(' ')\n",
    "            if len(set(categorysublist).intersection(frConstraints))>0:\n",
    "                keepIndex.append(index)\n",
    "                uniqueCategories.append(cat)\n",
    "                break\n",
    "            \n",
    "        totalIndex=index\n",
    "    \n",
    "    remIndex=list(set(range(totalIndex+1))-set(keepIndex))\n",
    "    data=data.drop(data.index[remIndex]).reset_index(drop=True)\n",
    "    return data,list(set(uniqueCategories))\n",
    "    \n",
    "all_data=JsontoDataFrame('getData/fbData.json')\n",
    "food_data,unique_categories=filterFoodRelated(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Label Binarizer Encoding Categories\n",
    "from sklearn import preprocessing\n",
    "lb=preprocessing.LabelBinarizer()\n",
    "lb.fit(unique_categories)\n",
    "\n",
    "def orCategories(bcat1,bcat2):\n",
    "    \"\"\"\n",
    "    Oring Category Codes \n",
    "    \"\"\"\n",
    "    result_cat=[]\n",
    "    for val1,val2 in zip(bcat1,bcat2):\n",
    "        if val1==1 or val2==1:\n",
    "            result_cat.append(1)\n",
    "        else:\n",
    "            result_cat.append(0)\n",
    "    #print 'res',result_cat\n",
    "    return result_cat\n",
    "\n",
    "def addBinaryCategoryData(data):\n",
    "    \"\"\"\n",
    "    Finding Binary Category Codes of all entries\n",
    "    \"\"\"\n",
    "    binary_category=[]\n",
    "    for catlist in data[\"Category\"]:\n",
    "        final_category=[0]*len(lb.classes_)\n",
    "        for cat in catlist:\n",
    "            if cat in unique_categories:\n",
    "                #print cat\n",
    "                binary_encoded_cat=lb.transform([str(cat)])[0]\n",
    "                finalcat=orCategories(final_category,binary_encoded_cat)\n",
    "                binary_category.append(finalcat)\n",
    "    return binary_category\n",
    "\n",
    "food_data['Category Code']=pd.Series(addBinaryCategoryData(food_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding Neigbouring Food related Joints\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine_dist(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    m = 6367 * c*1000\n",
    "    return m\n",
    "\n",
    "\n",
    "def findNeighbors(data,target_latitude,target_longitude,distance,is_food_related=True):\n",
    "    \"\"\"\n",
    "    Finding Neighbors to a given point on map\n",
    "    \"\"\"\n",
    "    neighbor_name=[]\n",
    "    neighbor_category=[0]*len(lb.classes_)\n",
    "    neighbor_checkins=0\n",
    "    if is_food_related:\n",
    "        for latitude,longitude,name,binary_category,check_in in zip(data['Latitude'],data['Longitude'],data['Name'],data['Category Code'],data['Check-Ins']):\n",
    "            neighbor_latitide=latitude\n",
    "            neighbor_longitude=longitude\n",
    "            if haversine_dist(target_longitude,target_latitude,neighbor_longitude,neighbor_latitide) < distance and target_longitude!=neighbor_longitude and neighbor_latitide!=target_latitude:\n",
    "                neighbor_name.append(name)\n",
    "                if is_food_related:\n",
    "                    neighbor_category=orCategories(neighbor_category,binary_category)\n",
    "                neighbor_checkins=neighbor_checkins+check_in\n",
    "    else:\n",
    "        for latitude,longitude,name,check_in in zip(data['Latitude'],data['Longitude'],data['Name'],data['Check-Ins']):\n",
    "            neighbor_latitide=latitude\n",
    "            neighbor_longitude=longitude\n",
    "            if haversine_dist(target_longitude,target_latitude,neighbor_longitude,neighbor_latitide) < distance and target_longitude!=neighbor_longitude and neighbor_latitide!=target_latitude:\n",
    "                neighbor_name.append(name)\n",
    "                neighbor_checkins=neighbor_checkins+check_in\n",
    "    return neighbor_name,neighbor_category,neighbor_checkins\n",
    "         \n",
    "def findAllNeighbors(distance,is_food_related=True,*data):\n",
    "    DISTANCE=distance\n",
    "    all_neighbour_name=[]\n",
    "    all_neighbour_category=[]\n",
    "    all_neighbour_checkins=[]\n",
    "    if is_food_related:\n",
    "        for lat,lon in zip(data[0]['Latitude'],data[0]['Longitude']):\n",
    "            neighbor_name,neighbor_category,neighbor_checkins=findNeighbors(data[0],lat,lon,DISTANCE,True)\n",
    "            all_neighbour_name.append(neighbor_name)\n",
    "            all_neighbour_category.append(neighbor_category)\n",
    "            all_neighbour_checkins.append(neighbor_checkins)\n",
    "    \n",
    "    else:\n",
    "        food_related_joints=data[0]['Name']\n",
    "        for lat,lon,name in zip(data[1]['Latitude'],data[1]['Longitude'],data[1]['Name']):\n",
    "            #Error in this line\n",
    "            #print name in food_related_joints returns false\n",
    "            if name[0] in food_related_joints[0]:\n",
    "                for lat,lon in zip(data[1]['Latitude'],data[1]['Longitude']):\n",
    "                    neighbor_name,neighbor_category,neighbor_checkins=findNeighbors(data[1],lat,lon,DISTANCE,False)\n",
    "                    all_neighbour_name.append(neighbor_name)\n",
    "                    all_neighbour_checkins.append(neighbor_checkins)  \n",
    "\n",
    "    return all_neighbour_name,all_neighbour_category,all_neighbour_checkins\n",
    "\n",
    "    \n",
    "\n",
    "def findAverageNeighborCheckIns(data,is_food_related=True):\n",
    "    average_neigbor_checkins=[]\n",
    "    if is_food_related:\n",
    "        column_total_check_ins='Food-Related Neighbor Total Check-Ins'\n",
    "        column_neigbor_names='Food-Related Neighbor Names'\n",
    "    else:\n",
    "        column_total_check_ins='All Neighbor Total Check-Ins'\n",
    "        column_neigbor_names='All Neighbor Names'\n",
    "    for neigbors,check_ins in zip(data[column_neigbor_names],data[column_total_check_ins]):\n",
    "        average_neigbor_checkins.append(check_ins/len(neigbors))\n",
    "    return average_neigbor_checkins\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Food Related DataFrame Modification\n",
    "all_neighbour_name,all_neighbour_category,all_neighbour_checkins=findAllNeighbors(1000,True,food_data,all_data) \n",
    "\n",
    "food_data['Food-Related Neighbor Names']=pd.Series(all_neighbour_name)\n",
    "food_data['Food-Related Neighbor Category Codes']=pd.Series(all_neighbour_category)\n",
    "food_data['Food-Related Neighbor Total Check-Ins']=pd.Series(all_neighbour_checkins)\n",
    "#food_data.drop('Food-Related Neighbor Check-Ins', axis=1, inplace=True)\n",
    "food_data['Food-Related Neighbor Average Check-Ins']=pd.Series(findAverageNeighborCheckIns(food_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All Neighbors DataFrame Modification\n",
    "all_neighbour_name,all_neighbour_category,all_neighbour_checkins=findAllNeighbors(1000,False,food_data,all_data) \n",
    "\n",
    "food_data['All Neighbor Names']=pd.Series(all_neighbour_name)\n",
    "food_data['All Neighbor Total Check-Ins']=pd.Series(all_neighbour_checkins)\n",
    "food_data['All Neighbor Average Check-Ins']=pd.Series(findAverageNeighborCheckIns(food_data,False))\n",
    "#food_data.drop('All Neighbor Category Codes', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Rearranging Columns\n",
    "food_data=food_data[['Name','Category','Likes','Check-Ins','Latitude','Longitude','Category Code','Food-Related Neighbor Names','Food-Related Neighbor Category Codes',\n",
    "                    'Food-Related Neighbor Total Check-Ins','Food-Related Neighbor Average Check-Ins','All Neighbor Names','All Neighbor Total Check-Ins'\n",
    "                    ,'All Neighbor Average Check-Ins']]\n",
    "data_of_interest=food_data[['Name','Category','Likes','Check-Ins','Category Code','Food-Related Neighbor Category Codes',\n",
    "                    'Food-Related Neighbor Total Check-Ins','Food-Related Neighbor Average Check-Ins','All Neighbor Total Check-Ins'\n",
    "                    ,'All Neighbor Average Check-Ins']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transfering to csv\n",
    "data_of_interest.to_csv('Final Data.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=data_of_interest[['Category Code','Food-Related Neighbor Category Codes','Food-Related Neighbor Total Check-Ins'\n",
    "                         ,'Food-Related Neighbor Average Check-Ins','All Neighbor Total Check-Ins','All Neighbor Average Check-Ins']]\n",
    "Y_train=data_of_interest[['Check-Ins']]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def convertBinaryArrayToNumber(array):\n",
    "    number=0\n",
    "    array.reverse()\n",
    "    i=0\n",
    "    for val in array:\n",
    "        number=number+val*pow(2,i)\n",
    "        i=i+1\n",
    "    return number\n",
    "        \n",
    "def convertCodeToNumber(data):\n",
    "    category_decode=[]\n",
    "    neighbor_category_decode=[]\n",
    "    for cat_code,n_cat_code in zip(data['Category Code'],data['Food-Related Neighbor Category Codes']):\n",
    "        category_decode.append(convertBinaryArrayToNumber(cat_code))\n",
    "        neighbor_category_decode.append(convertBinaryArrayToNumber(n_cat_code))\n",
    "        #category_decode.append(lb.inverse_transform(cat_code))\n",
    "        #neighbor_category_decode.append(ib.inverse_transform(n_cat_code))\n",
    "        \n",
    "    return category_decode,neighbor_category_decode\n",
    "        \n",
    "\n",
    "category_decode,neighbor_category_decode=convertCodeToNumber(X_train)  \n",
    "X_train['Category Code']=pd.Series(category_decode)\n",
    "X_train['Food-Related Neighbor Category Codes']=pd.Series(neighbor_category_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Converting float to int\n",
    "#uncomment it once for first run\n",
    "Y_train.to_csv('Target.csv')\n",
    "Y_train=pd.read_csv('Target.csv',dtype='float64')\n",
    "Y_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "Y_train=Y_train.values.astype(int)\n",
    "X_train=X_train.values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing models\n",
    "* Linear Regressor\n",
    "* Ridge\n",
    "* Support Vector Machine\n",
    "\n",
    "Support vector gives 0 error and hence we will choose support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing out models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "linearrgr = LinearRegression()\n",
    "linearrgr.fit(X_train,Y_train)\n",
    "ypred=linrgr.predict(X_train).astype(int)\n",
    "mean_absolute_error(ypred,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RidgeRegression\n",
    "from sklearn import linear_model \n",
    "\n",
    "ridge=linear_model.Ridge(alpha=0.5)\n",
    "ridge.fit(X_train,Y_train)\n",
    "yprred=ridge.predict(X_train).astype(int)\n",
    "mean_absolute_error(yprred,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support vector machines\n",
    "from sklearn import svm\n",
    "\n",
    "supvecmac=svm.SVC()\n",
    "supvecmac.fit(X_train,Y_train)\n",
    "yprred=supvecmac.predict(X_train)\n",
    "\n",
    "mean_absolute_error(yprred,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TrainedModel.pkl',\n",
       " 'TrainedModel.pkl_01.npy',\n",
       " 'TrainedModel.pkl_02.npy',\n",
       " 'TrainedModel.pkl_03.npy',\n",
       " 'TrainedModel.pkl_04.npy',\n",
       " 'TrainedModel.pkl_05.npy',\n",
       " 'TrainedModel.pkl_06.npy',\n",
       " 'TrainedModel.pkl_07.npy',\n",
       " 'TrainedModel.pkl_08.npy',\n",
       " 'TrainedModel.pkl_09.npy',\n",
       " 'TrainedModel.pkl_10.npy',\n",
       " 'TrainedModel.pkl_11.npy']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(supvecmac,'TrainedModel.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
